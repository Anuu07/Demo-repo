{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c1d506-2686-4761-a4a9-32cdb045b923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: IMG JBP - Ideal Management Group | IT Training & Consulting in Jabalpur\n",
      "Ideal Management GroupSince 2002\n",
      "no. of links 1\n",
      "Home\n",
      "no. of links 2\n",
      "About\n",
      "no. of links 3\n",
      "Courses\n",
      "no. of links 4\n",
      "AI Bootcamp\n",
      "no. of links 5\n",
      "Plans\n",
      "no. of links 6\n",
      "Contact\n",
      "no. of links 7\n",
      "WhatsApp\n",
      "no. of links 8\n",
      "Start Your Journey\n",
      "no. of links 9\n",
      "Book Free Demo\n",
      "no. of links 10\n",
      "Claim Offer Now - WhatsApp\n",
      "no. of links 11\n",
      "Enroll Now\n",
      "no. of links 12\n",
      "Enroll Now\n",
      "no. of links 13\n",
      "Enroll Now\n",
      "no. of links 14\n",
      "View All Premium CoursesView All Courses\n",
      "no. of links 15\n",
      "Join AI Revolution\n",
      "no. of links 16\n",
      "Start Your Success Story\n",
      "no. of links 17\n",
      "\n",
      "no. of links 18\n",
      "\n",
      "no. of links 19\n",
      "\n",
      "no. of links 20\n",
      "About Us\n",
      "no. of links 21\n",
      "Courses\n",
      "no. of links 22\n",
      "AI Bootcamp\n",
      "no. of links 23\n",
      "Plans\n",
      "no. of links 24\n",
      "Contact\n",
      "no. of links 25\n",
      "Chat with us instantly!\n",
      "no. of links 26\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://imgjbp.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "#create beautifulsoup object\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "#Find elements\n",
    "title = soup.title.string\n",
    "paragraphs = soup.find_all('a')#link\n",
    "\n",
    "print(f\"Title: {title}\")\n",
    "i=0\n",
    "for p in paragraphs:\n",
    "    i+=1\n",
    "    print(p.text)\n",
    "    print(\"no. of links\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad061f57-5ea8-4bf1-bc0b-e394ef4ea138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeautifulSoup is successfully installed!\n",
      "\n",
      "Testing with a sample webpage...\n",
      "An unexpected error occurred: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "Please check your internet connection and try again.\n"
     ]
    }
   ],
   "source": [
    "'''Key features:\n",
    "\n",
    "Parsing HTML/XML\n",
    "Navigating the parse tree\n",
    "Searching the parse tree\n",
    "Modifying the parse tree\n",
    "\n",
    "\n",
    "Common methods:\n",
    "\n",
    "find(): Finds the first occurrence of a tag\n",
    "find_all(): Finds all occurrences of a tag\n",
    "select(): Uses CSS selectors to find elements'''\n",
    "\n",
    "\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "\n",
    "    print(\"BeautifulSoup is successfully installed!\")\n",
    "    #print(f\"BeautifulSoup version: {BeautifulSoup.version}\")\n",
    "\n",
    "    print(\"\\nTesting with a sample webpage...\")\n",
    "    response = requests.get(\"http://imgjbp.com\")\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    title = soup.find('h1')\n",
    "    if title:\n",
    "        print(f\"Successfully parsed webpage. Title: {title.text}\")\n",
    "    else:\n",
    "        print(\"Webpage parsed, but no h1 tag found.\")\n",
    "\n",
    "    print(\"\\nInstallation check complete. BeautifulSoup is ready to use!\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"BeautifulSoup or requests is not installed correctly.\")\n",
    "    print(\"Please make sure you have installed both libraries:\")\n",
    "    print(\"pip install beautifulsoup4 requests\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    print(\"Please check your internet connection and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a26d2e-5004-4ce0-9a34-6c6af4b06873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: My Simple Webpage\n",
      "H1 tag: Welcome to My Webpage\n",
      "\n",
      "Paragraphs:\n",
      "This is a paragraph with some bold text.\n",
      "Here's another paragraph.\n",
      "\n",
      "List items:\n",
      "First item\n",
      "Second item\n",
      "Third item\n",
      "\n",
      "Bold text in first content paragraph: bold text\n"
     ]
    }
   ],
   "source": [
    "'''We start by importing BeautifulSoup.\n",
    "We define a simple HTML document as a string. In real-world scenarios, you'd typically get this by reading a file or making a web request.\n",
    "We create a BeautifulSoup object by passing the HTML document and specifying the parser to use ('html.parser' is Python's built-in HTML parser).\n",
    "We then use various BeautifulSoup methods to extract information:\n",
    "\n",
    "soup.title.string: Gets the text within the <title> tag.\n",
    "soup.h1.string: Gets the text within the first <h1> tag.\n",
    "soup.find_all('p'): Finds all <p> tags in the document.\n",
    "soup.find_all('li'): Finds all <li> tags.\n",
    "soup.find('p', class_='content'): Finds the first <p> tag with class 'content'.\n",
    "first_content_para.find('b'): Finds the <b> tag within the first content paragraph.\n",
    "\n",
    "\n",
    "We print out the extracted information.\n",
    "\n",
    "This script demonstrates the basic usage of BeautifulSoup, including:\n",
    "\n",
    "Parsing HTML\n",
    "Accessing tags directly (like soup.title)\n",
    "Using find_all() to get multiple elements\n",
    "Using find() to get a single element with specific attributes\n",
    "Navigating the parse tree (finding a tag within another tag)\n",
    "Extracting text from tags\n",
    "\n",
    "When you run this script, it will parse the HTML and print out the extracted information.'''\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# A sample HTML document\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>My Simple Webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Welcome to My Webpage</h1>\n",
    "    <p class=\"content\">This is a paragraph with some <b>bold text</b>.</p>\n",
    "    <p class=\"content\">Here's another paragraph.</p>\n",
    "    <ul>\n",
    "      <li>First item</li>\n",
    "      <li>Second item</li>\n",
    "      <li>Third item</li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "# Extract and print the title\n",
    "print(\"Title:\", soup.title.string)\n",
    "\n",
    "# Find and print the h1 tag\n",
    "print(\"H1 tag:\", soup.h1.string)\n",
    "\n",
    "# Find all paragraphs and print their text\n",
    "print(\"\\nParagraphs:\")\n",
    "for paragraph in soup.find_all('p'):\n",
    "    print(paragraph.text)\n",
    "\n",
    "# Find all list items and print their text\n",
    "print(\"\\nList items:\")\n",
    "for item in soup.find_all('li'):\n",
    "    print(item.string)\n",
    "\n",
    "# Find the first paragraph with class 'content' and print its bold text\n",
    "first_content_para = soup.find('p', class_='content')\n",
    "if first_content_para:\n",
    "    bold_text = first_content_para.find('b')\n",
    "    if bold_text:\n",
    "        print(\"\\nBold text in first content paragraph:\", bold_text.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5527d4-6961-4ded-8c11-353b32235611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webscraping = website se data nikalana without going to website"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
